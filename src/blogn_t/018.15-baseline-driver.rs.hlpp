pub struct PosteriseGpu {
	// ...
	device: vulkanalia::Device,
	compute_pipeline: vulkanalia::Pipeline,     // posterise.hlsl
	compute_pipeline_mul: vulkanalia::Pipeline, // posterise_mul.hlsl

	memory_type_index: u32,                 // HOST_VISIBLE & HOST_COHERENT
	buffer_outputs: BufferBundle,           // [[vk::binding(0)]] SB<float3>          outputs;
	buffer_params: BufferBundle,            // [[vk::binding(1)]] SB<params_t>        params;
	buffer_known_rgbs_bundle: BufferBundle, // [[vk::binding(2)]] SB<known_rgbs_pack> known_rgbs_bundle;
	buffer_known_rgbs_freqs: BufferBundle,  // [[vk::binding(3)]] SB<uint4>           known_rgbs_freqs;

	buffer_outputs_map: &'static mut [[f32; 4]; 0xFFFFFF + 1],
	buffer_params_map: &'static mut ParamsT,
}

fn PosteriseGpu::susmit(&mut self, known_rgbs: &[(u32, Lab, u32)], radiussy: f32, freq_weighting: bool, outputs: &mut [Lab; 0xFFFFFF + 1]) {
#SMALL_START#
	self.buffer_known_rgbs_bundle = self.ensure_buffer(self.buffer_known_rgbs_bundle, known_rgbs.len() * mem::size_of::<KnownRgbsPack>());
	assert!(mem::size_of::<KnownRgbsPack>() == 4 * 4);
#SMALL_END#
	if freq_weighting {
		self.buffer_known_rgbs_freqs = self.ensure_buffer(self.buffer_known_rgbs_freqs, known_rgbs.len().div_ceil(4) * mem::size_of::<[f32; 4]>());
	}

#SMALL_START#
	self.buffer_params_map = ParamsT {
		known_rgbs_len: known_rgbs.len(),
		radiussy: radiussy,
		iter_limit: -1,
	};

	let buffer_known_rgbs_bundle_map = self.device.map_memory(self.buffer_known_rgbs_bundle);
	let known_rgbs_bundle: &mut [KnownRgbsPack] = slice::from_raw_parts_mut(buffer_known_rgbs_bundle_map, known_rgbs.len());
	for ((rgb, lab, _), dest_lab) in known_rgbs.iter().zip(known_rgbs_bundle.iter_mut()) {
		dest_lab = KnownRgbsPack {
			rgb: rgb,
			lab: lab,
		};
	}
	self.device.unmap_memory(self.buffer_known_rgbs_bundle.buffer_memory);
#SMALL_END#

	if freq_weighting {
		let buffer_known_rgbs_freqs_map = self.device.map_memory(self.buffer_known_rgbs_freqs);
		let known_rgbs_freqs: &mut [[u32; 4]] = slice::from_raw_parts_mut(buffer_known_rgbs_freqs_map, known_rgbs.len().div_ceil(4));
		for ((_, _, freq), dest_freq) in known_rgbs.iter().zip(known_rgbs_freqs.iter_mut().flatten()) {
			dest_freq = freq;
		}
		self.device.unmap_memory(self.buffer_known_rgbs_freqs.buffer_memory);
	}

	self.descriptor_set = self.device.update_descriptor_sets(vk::WriteDescriptorSet{[/* â€¦ */, self.buffer_known_rgbs_freqs]});

	self.device.cmd_bind_pipeline(self.cmd_buffer, vk::PipelineBindPoint::COMPUTE,
		if freq_weighting { self.compute_pipeline_mul } else { self.compute_pipeline });
	// cmd_pipeline_barrier(HOST -> COMPUTE_SHADER: also self.buffer_known_rgbs_freqs: HOST_WRITE -> SHADER_READ)
	self.device.cmd_dispatch(self.cmd_buffer, known_rgbs.len().div_ceil(64) /* x */, 1 /* y */, 1 /* z */);

	self.device.queue_submit(self.compute_queue, &[vk::SubmitInfo::builder().command_buffers(&[self.cmd_buffer])], self.fence);
	self.device.wait_for_fences(&[self.fence], true, u64::MAX).unwrap();

#SMALL_START#
	for (rgb, _, _) in known_rgbs {
		outputs[rgb].l = self.buffer_outputs_map[rgb][0];
		outputs[rgb].a = self.buffer_outputs_map[rgb][1];
		outputs[rgb].b = self.buffer_outputs_map[rgb][2];
	}
#SMALL_END#
}
